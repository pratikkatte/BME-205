{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-fruit",
   "metadata": {},
   "source": [
    "# Finding CRISPR arrays\n",
    "## Specification\n",
    "## Program Name: randomizedMotifSearch.py\n",
    "\n",
    "## Input/Output: STDIN, STDOUT\n",
    "\n",
    "## Options:\n",
    "\n",
    "- -i iterations (int)\n",
    "- -k motif length (int)\n",
    "- -p pseudocount (float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-suicide",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex: python randomizedMotifSearch.py -i 1000 -k 13 -p 1 < input.fa > output.out\n",
    "\n",
    "Inspection Notebook example:\n",
    "main ( \"input.fa\", options = [ \"-i 1000\", \"-k 13\", \"-p 1\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-population",
   "metadata": {},
   "source": [
    "## Background\n",
    "CRISPR arrays exist in most archaeal species and many bacterial species. The arrays are encoded in chromosomal DNA as direct repeats (DR) that flank sequences (spacers) that provide immunity against invading plasmids, viral sequences, and other foreign DNA .. and RNA. These arrays can be short, comprising 1-2 spacers, or they can contain hundreds of spacer elements. The arrays are punctuated by these DR sequences. The promoter element seems to be upstream of the array, and initiates transcription of the associated RNA strand that is then cleaved and those spacers are loaded into protein machines that provide specific targeting of the associated invader should it be found. That targeting causes cleavage of the foreign DNA in known cases.\n",
    "\n",
    "There are three main classes of CRISPR systems; these are type I,II and III, and are established based on the associated protein machines - actually the specific genes that encode for them. In the archaea, only type I and III have been found so far, while in bacteria, all three types have been seen. One of those types, type II, exists in a few species, including _Streptococcus pyogenes_, which encodes for a type II system. The specific gene that is used to classify this system is named Cas9.\n",
    "\n",
    "We see cases where Cas genes, and sometimes CRISPR arrays, exist in a viral sequence. This, of course, opens many questions about the role of the CRISPR system with respect to viruses - why would a virus carry an immune defense that targets viral sequence? The existence of these arrays suggests that the CRISPR system itself might be mobile. How does the system get established, and how does the surrounding transcription machinery get encoded on the chromosome?\n",
    "\n",
    "For this assignment, we will work to find the promoter motif. We would expect that this promoter motif and an associated B recognition element (BRE) would be present in archaeal species. What is that motif, and where is it located relative to transcription start?\n",
    "\n",
    "We know little about the sequence specifics of the promoter element, though it seems to be about 13 nucleotides in length. In Pyrobaculum species, genes are packed quite tightly, so we can look upstream of the array by about 50 bases to see if a common motif sequence might exist. We need to assume that some mutations can be tolerated in that sequence.\n",
    "\n",
    "## Null model\n",
    "In prior years, we included an option that scrambled the input sequences before running to find a best score. This would effectively eliminate any signal that might be present in the data, while preserving the overall composition of the sequences. We would then compare the best score achieved without scrambling to the score achieved with scrambling. The information that remains in a scrambled set of sequences is only the base level composition of the sequences. We now use Relative Entropy to do this comparison of our experimental model(P) to our null(Q):\n",
    "\n",
    "$Q=Pr_{s\\in\\lbrace{ACTG}\\rbrace}(s)=\\frac{count(s)}{N}$\n",
    "\n",
    "We can then use relative entropy to find a score relative to the base level composition by:\n",
    "\n",
    "$REscore = \\sum_{i=0}^{cols}\\sum^{j \\in ACGT}P_{i}(j)\\log_{2}(\\frac{P_{i}(j)}{Q(j)} )$\n",
    "\n",
    "## Assignment\n",
    "__Write a BME205 style program (.py file)__ that is based on the Randomized Motif Search presented in class/videos and is described in Chapter 2 of the text. Your program should accept a fasta file that contains multiple fasta records as input (STDIN), and your program will then output (STDOUT) the consensus sequence and associated profile score. The score will be the sum of encoding costs (entropies) across each position in the final profile. We will use pseudocounts for this assignment, as described in the text (p. 86-89), and we will need an option to provide the number of pseudocounts (-p).\n",
    "\n",
    "__Produce a notebook that should be fully runable for use during inspections.__\n",
    "\n",
    "I find it easier to accumulate counts rather than calculating a probability based profile. This will also make it a bit easier to deal with pseudocounts when scoring your count-based profile.\n",
    "\n",
    "$score = \\sum_{i=0}^{cols}\\sum^{j \\in ACGT}P_{i}(j)\\log_{2}(\\frac{P_{i}(j)}{Q(j)} )$\n",
    "\n",
    "Randomized Motif Search (p. 93) can be easily trapped in local minima, so we will need to iterate some number of times to find a trajectory that produces the best results. This will need to be an option (-i) that establishes the iteration number.\n",
    "\n",
    "We also don't know the appropriate motif length that we are looking for, so we need an option (-k) to specify this.\n",
    "\n",
    "The full command line string should then look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomizedMotifSearch.py -i=100000 -p=1 -k=13 <somefile.fa >someOutputFile.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-three",
   "metadata": {},
   "source": [
    "your program will need to use standard OO style, include docstrings and be well commented. It must run! \n",
    "\n",
    "I will provide a few fasta files that present the upstream 50 bases from species of the Pyrobaculum group. It is possible that the promotor+BRE that we are looking for is conserved across these species, maybe not perfectly though. Providing more data to a single run may be useful.\n",
    "\n",
    "I do have expression data for these species, so we know that not all of these arrays are functional - at least under the conditions when I grew them.\n",
    "\n",
    "Your program should output the final score achieved, along with the associated consensus motif.\n",
    "\n",
    "## Extra Credit\n",
    "The following optional features would be useful and considered for a combined extra 5 points:\n",
    "\n",
    "1) -g Use Gibbs sampling to find the optimal consensus motif.\n",
    "\n",
    "2) -m Print the specific motif and the name of the contributing sequence for each of the participating fasta records.\n",
    "\n",
    "Each of these options should only be true when the flag is specified by the user (ie. you shouldn't have to explicitly state True/False on the commandline).\n",
    "\n",
    "Submit your working program to Canvas.\n",
    "\n",
    "## Notes:\n",
    "\n",
    "1) It is likely that we will need to amend this assignment as we work with it.\n",
    "\n",
    "2) Sept-2021 eliminated the need for scrambling sequences by using relative entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-remark",
   "metadata": {},
   "source": [
    "## Inspection intro\n",
    "\n",
    "- What data structure did you use to hold your sequence motifs (DNA)?\n",
    " > I used lists to hold the sequence motifs.\n",
    "\n",
    "    \n",
    "- Is your profile  structure based on counts or frequencies? \n",
    " > My profile structure is based on counts.\n",
    "\n",
    "- Where did you implement iterations (mostly why did you choose this)?\n",
    "> The iterations in the Random Motif Search Algorithm are implemented to repeatedly perform the motif discovery process. The choice of implementing iterations is primarily driven by the need to explore different possibilities and iteratively refine the motifs. Here's why iterations are crucial and why they are chosen in this algorithm\n",
    "- If you implemented Gibbs Sampling, how did you implement recomputing of the profile and motif?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-civilization",
   "metadata": {},
   "source": [
    "## Inspection Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d86cf-b572-4334-b706-2f8c7d00f0c6",
   "metadata": {},
   "source": [
    "I was stuck with relative entropy and the use of pseudocounts. Kerney, Paul, and I discussed and understood the concept of relative entropy, as well as how to calculate the null distribution, and how to incorporate pseudocounts into the calculations. They were instrumental in helping me correct my code by adding pseudocounts to the existing base counts in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d60fcd73-07ec-4b69-9a0e-0e5fba6ebb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Consencus GAAAAACTTAAAA with score - 8.217968381511612\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class FastAreader:\n",
    "    def __init__(self, fname=''):\n",
    "        '''contructor: saves attribute fname '''\n",
    "\n",
    "        self.fname = fname\n",
    "        self.fileH = None\n",
    "\n",
    "    def doOpen(self):\n",
    "        if self.fname == '':\n",
    "            return sys.stdin\n",
    "        else:\n",
    "            return open(self.fname)\n",
    "\n",
    "    def readFasta(self):\n",
    "\n",
    "        header = ''\n",
    "        sequence = ''\n",
    "\n",
    "        with self.doOpen() as self.fileH:\n",
    "\n",
    "            header = ''\n",
    "            sequence = ''\n",
    "\n",
    "            # skip to first fasta header\n",
    "            line = self.fileH.readline()\n",
    "            while not line.startswith('>'):\n",
    "                line = self.fileH.readline()\n",
    "            header = line[1:].rstrip()\n",
    "\n",
    "            for line in self.fileH:\n",
    "                if line.startswith('>'):\n",
    "                    yield header, sequence\n",
    "                    header = line[1:].rstrip()\n",
    "                    sequence = ''\n",
    "                else:\n",
    "                    sequence += ''.join(line.rstrip().split()).upper()\n",
    "        yield header, sequence\n",
    "\n",
    "class CommandLine():\n",
    "    \"\"\"\n",
    "    Handle the command line, usage and help requests.\n",
    "\n",
    "    CommandLine uses argparse, now standard in 2.7 and beyond.\n",
    "    it implements a standard command line argument parser with various argument options,\n",
    "    a standard usage and help, and an error termination mechanism do-usage_and_die.\n",
    "\n",
    "    attributes:\n",
    "    all arguments received from the commandline using .add_argument will be\n",
    "    available within the .args attribute of object instantiated from CommandLine.\n",
    "    For example, if myCommandLine is an object of the class, and requiredbool was\n",
    "    set as an option using add_argument, then myCommandLine.args.requiredbool will\n",
    "    name that option.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inOpts=None):\n",
    "        \"\"\"\n",
    "        CommandLine constructor.\n",
    "        There are three arguments that are passed to the class Consensus():\n",
    "            -i iterations (int)\n",
    "            -k motif length (int)\n",
    "            -p pseudocount (float)\n",
    "        \"\"\"\n",
    "        import argparse\n",
    "        self.parser = argparse.ArgumentParser(\n",
    "            description='Program prolog - a brief description of what this thing does',\n",
    "            epilog='Program epilog - some other stuff you feel compelled to say',\n",
    "            add_help=True,  # default is True\n",
    "            prefix_chars='-',\n",
    "            usage='python randomizedMotifSearch.py -i int --maxMotif int --cutoff int < input.fa > output.out'\n",
    "        )\n",
    "        # Be sure to go over the argument information again\n",
    "        self.parser.add_argument('-i', type=int, action='store',\n",
    "                                 help='number of iterations (int)')\n",
    "        self.parser.add_argument('-k', type=int, action='store',\n",
    "                                 help='motif length (int)')\n",
    "        self.parser.add_argument('-p', type=int, action='store',\n",
    "                                 help='pseudocount (float)')\n",
    "\n",
    "        if inOpts is None:\n",
    "            self.args = self.parser.parse_args()\n",
    "        else:\n",
    "            self.args = self.parser.parse_args(inOpts)\n",
    "\n",
    "class Genome:\n",
    "    \"\"\"\n",
    "    This class helps in initializing and storing different attributes that can be used across several functions across the class. \n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, i, k, p, input_sequences):\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        self.iterations = i\n",
    "        self.pseudo_counts = p\n",
    "        self.kmer_size = k\n",
    "        self.input_sequences = input_sequences\n",
    "        self.best_score = 0\n",
    "        self.best_motif = []\n",
    "        self.null_distribution = self.null_model_distribution()\n",
    "        \n",
    "    def newMotif(self, profile):\n",
    "        \"\"\"\n",
    "        Function: To get new set of motifs from the existing profiles.\n",
    "        input: profile of a set of existing selected motifs. \n",
    "        \n",
    "        return: new set of motifs that generated using the counts of bases from the profile. \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        new_motif = []\n",
    "        for seq in self.input_sequences:\n",
    "            best_prod_score = 0\n",
    "            best_motif = []\n",
    "\n",
    "            for i in range(0, len(seq)-self.kmer_size+1):\n",
    "                motif = seq[i:i+self.kmer_size]\n",
    "                product_score = 1\n",
    "                for pos, base in enumerate(motif):\n",
    "                    count_from_profile = profile[base][pos]\n",
    "                    product_score = product_score * count_from_profile\n",
    "                if product_score > best_prod_score:\n",
    "                    best_prod_score = product_score\n",
    "                    best_motif = motif\n",
    "                \n",
    "            new_motif.append(best_motif)\n",
    "        \n",
    "        return new_motif\n",
    "\n",
    "    def selectRandomKmer(self, input_sequence_list):\n",
    "        \"\"\"\n",
    "        Function: select random kmers from all the reads in the fast file. \n",
    "        input: input sequence list from the fasta file.\n",
    "        \n",
    "        return: set of random motifs of size k.\n",
    "        \"\"\"\n",
    "        \n",
    "        rand_kmer_array = []\n",
    "        \n",
    "        for sequence in input_sequence_list:\n",
    "            \n",
    "            rand_index = random.randint(0, len(sequence)-self.kmer_size)\n",
    "            \n",
    "            random_kmer = sequence[rand_index:rand_index+self.kmer_size]\n",
    "            rand_kmer_array.append(random_kmer)\n",
    "        return rand_kmer_array\n",
    "    \n",
    "    def null_model_distribution(self):\n",
    "        \"\"\"\n",
    "        Function that returns a dictionary of number of counts of every bases {A,C,G,T} in the complete genome sequence.\n",
    "        \"\"\"\n",
    "        input_seq = self.input_sequences\n",
    "        joined_input_seq = \"\".join(input_seq)\n",
    "        col_counter = dict(Counter(joined_input_seq))\n",
    "\n",
    "        null_distribution = {k: (v+self.pseudo_counts) / (len(joined_input_seq)+ self.pseudo_counts*4) for k, v in col_counter.items()}\n",
    "        \n",
    "        return null_distribution\n",
    "\n",
    "\n",
    "    def make_profile_from_kmers(self, input_motifs):\n",
    "        \"\"\"\n",
    "        The function calculates the distribution of bases for the provided input set of motifs. \n",
    "\n",
    "        input: set of motifs of kmer-size k. \n",
    "        return: a maxtrix of size 4xk. where the four rows are the bases {A,C,G,T} and the columns of size k each having the counts of bases.\n",
    "        \"\"\"\n",
    "        profile_dict = {\n",
    "            'A': [],\n",
    "            'G': [],\n",
    "            'C': [],\n",
    "            'T': []\n",
    "        }\n",
    "\n",
    "        for i in range(self.kmer_size):\n",
    "            col = []\n",
    "            for j in range(len(input_motifs)):\n",
    "                col.append(input_motifs[j][i])\n",
    "            col_counter = dict(Counter(col))\n",
    "            \n",
    "            nset = len(self.input_sequences)\n",
    "            profile_dict['A'].append(col_counter['A']+self.pseudo_counts if 'A' in col_counter else 0+self.pseudo_counts)\n",
    "            profile_dict['C'].append(col_counter['C']+self.pseudo_counts if 'C' in col_counter else 0+self.pseudo_counts)\n",
    "            profile_dict['T'].append(col_counter['T']+self.pseudo_counts if 'T' in col_counter else 0+self.pseudo_counts)\n",
    "            profile_dict['G'].append(col_counter['G']+self.pseudo_counts if 'G' in col_counter else 0+self.pseudo_counts)\n",
    "        return profile_dict\n",
    "    \n",
    "    def calcRelativeEntropy(self, input_motifs):\n",
    "        \"\"\"\n",
    "        The function considers the null model and compares it with the experimental model inorder to calculate the relative entropy.\n",
    "        The function also call the make_profile_from_kmers function to create profile from the provided input set of motifs. \n",
    "\n",
    "        Input: the set of motifs of kmer-size k. \n",
    "\n",
    "        return: the relative entropy score of the provided set of motifs and the profile of the motifs. \n",
    "\n",
    "        \"\"\"\n",
    "        relative_motif_score = 0\n",
    "\n",
    "        profile = self.make_profile_from_kmers(input_motifs)\n",
    "        for col in range(self.kmer_size):\n",
    "            for base in self.null_distribution:\n",
    "                if profile[base][col] != 0: \n",
    "                    pr = profile[base][col]/(len(self.input_sequences) + (4*self.pseudo_counts))\n",
    "                    relative_motif_score += pr * math.log2(pr / self.null_distribution[base])\n",
    "        return relative_motif_score, profile\n",
    "\n",
    "    def randomMotifSearch(self, input_seqs):\n",
    "        \"\"\"\n",
    "        The function iterates for self.iterations times and initially selects random motifs of kmers-size k, and creates profile to select the next set of motifs which will be compared with the \n",
    "        previous set of motifs using relative entropy score. The process is repeated until the best relative entropy score is found. \n",
    "\n",
    "        Input: input sequences of the whole fasta file. \n",
    "        return: prints the consensus and the best relative entropy score of the given input. \n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            \n",
    "            random_kmers = self.selectRandomKmer(input_seqs) # initialized kmers randomly with kmer-size -k\n",
    "            best_score_motif, best_profile = self.calcRelativeEntropy(random_kmers) # calculate the score of the randomly initialized kmers. Consider it as the best_score. \n",
    "            selected_motifs = random_kmers\n",
    "            while True:\n",
    "                new_motifs = self.newMotif(best_profile) # select new motifs from the current profile\n",
    "                new_score, new_profile = self.calcRelativeEntropy(new_motifs)\n",
    "                \n",
    "                if new_score > best_score_motif:\n",
    "                    selected_motifs = new_motifs\n",
    "                    best_score_motif = new_score\n",
    "                    best_profile = new_profile\n",
    "\n",
    "                    if best_score_motif > self.best_score:\n",
    "                        self.best_score = best_score_motif\n",
    "                        self.best_motif = selected_motifs\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        print(\"Found Consencus {} with score - {}\".format(self.printConsencus(self.best_motif), self.best_score))\n",
    "\n",
    "    def printConsencus(self, input_motifs):\n",
    "        \"\"\"\n",
    "        Function: Using the best motif found using randomsearch algorithm, the function returns the consensus from the profile of the motif. \n",
    "\n",
    "        Input: input_motif - is the best motif found from the randmom search algorithm.\n",
    "\n",
    "        return: the consensus motif of kmer-size k. \n",
    "        \"\"\"\n",
    "        motif_set = input_motifs\n",
    "        profile = self.make_profile_from_kmers(motif_set)\n",
    "        concensus = ''\n",
    "        for i in range(self.kmer_size):\n",
    "            max_prob = 0\n",
    "            max_base = 'A'\n",
    "            for base, probs in profile.items():\n",
    "                if probs[i] > max_prob:\n",
    "                    max_prob = probs[i]\n",
    "                    max_base = base\n",
    "            concensus+= max_base\n",
    "        return concensus\n",
    "\n",
    "def main(inFile=\"\", options = None):\n",
    "    ''' Setup necessary objects, read data and print the final report.'''\n",
    "    cl = CommandLine(options) # setup the command line\n",
    "    sourceReader = FastAreader(inFile) # setup the Fasta reader Object\n",
    "    sequenceList = []\n",
    "    for head, seq in sourceReader.readFasta():       # reading the fast file. \n",
    "        sequenceList.append(seq)\n",
    "    \n",
    "    thisGenome = Genome(cl.args.i, cl.args.k, cl.args.p, sequenceList)\n",
    "    thisGenome.randomMotifSearch(sequenceList)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # main()\n",
    "    inpFile = \"p1860Crisprs\"\n",
    "    main(inpFile, options = [ \"-i 1000\", \"-k 13\", \"-p 1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b778f4a-8e86-44a2-8e60-64582610dd77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
